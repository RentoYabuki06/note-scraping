# ðŸ“ Note Scraping

A Python tool for scraping articles from [note.com](https://note.com/yabukin_coffee/n/n09b9f19e05a6) and storing the extracted information in a Notion database. This tool helps content creators track and analyze their published articles.

## âœ¨ Features

- ðŸ” Automatically scrapes article data from note.com:
  - ðŸ“„ Title
  - ðŸ“… Publication date
  - â¤ï¸ Like count
  - ðŸ·ï¸ Hashtags used in articles
- ðŸ“Š Stores data in a structured Notion database for easy access and analysis
- ðŸ“‹ Uses Google Sheets as a source list for URLs to process in batch

## ðŸ”§ Requirements

- ðŸ Python 3.6+
- ðŸ“§ Google account (for using Google Sheets API)
- ðŸ§  Notion account with API access
- ðŸ“¦ Required Python packages:
  - `gspread`
  - `google-auth`
  - `notion-client`
  - `beautifulsoup4`
  - `requests`
  - `python-dotenv`

## ðŸš€ Setup

### 1ï¸âƒ£ **Create a Google Sheet**:
   - ðŸ“ Add URLs of note.com articles you want to track in a column
   - ðŸ”‘ Note the Sheet ID from the URL `https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit`

### 2ï¸âƒ£ **Set up Notion Integration**:
   - ðŸ”Œ Create a new integration at [Notion Integrations](https://www.notion.so/my-integrations)
   - ðŸ—ƒï¸ Create a database with the following properties:
     - `Title` (title type)
     - `Like` (number type)
     - `View` (number type)
     - `URL` (url type)
     - `Charnum` (number type)
     - `Category` (multi-select type)
     - `Publish` (date type)
   - ðŸ”— Connect your database with the integration
   - ðŸ“‹ Copy your database ID from the URL

### 3ï¸âƒ£ **Environment Setup**:
   - ðŸ“„ Create a `.env` file with the following variables:
     ```
     SPREADSHEET_ID="your_google_spreadsheet_id"
     SHEET_NAME="Sheet1"
     COLUMN_TO_READ=2
     START_ROW=2
     NOTION_API_KEY="your_notion_integration_key"
     DATABASE_ID="your_notion_database_id"
     ```

## ðŸƒâ€â™‚ï¸ Usage

### ðŸŒ Option 1: Run using Google Colab
1. ðŸ““ Open the provided Jupyter notebook in Google Colab
2. ðŸ’¾ Mount your Google Drive
3. ðŸ“‚ Set the working directory where your `.env` file is located
4. â–¶ï¸ Run all cells sequentially

### ðŸ’» Option 2: Run locally
1. âš™ï¸ Install required packages:
   ```bash
   pip install gspread google-auth notion-client beautifulsoup4 requests python-dotenv
   ```

2. ðŸ“œ Extract the Python code from the notebook into a script
3. ðŸš€ Run the script:
   ```bash
   python note_scraper.py
   ```

## âš™ï¸ How It Works

1. ðŸ“Š The tool reads URLs from your Google Sheet
2. ðŸ” For each URL, it scrapes note.com to extract article data
3. âœï¸ The data is formatted and added to your Notion database
4. ðŸ“ Progress and any errors are logged during execution

## âš ï¸ Limitations

- ðŸŒ Works specifically with note.com's current HTML structure
- ðŸ“Š Some values like View count and Character count are not implemented
- â±ï¸ Rate limits may apply when scraping many articles

## ðŸ”§ Troubleshooting

If you encounter errors:
- ðŸ” Verify your environment variables are set correctly
- âœ… Ensure your Notion database property names match exactly (case-sensitive)
- ðŸ”— Check that your note.com URLs are valid and accessible

---

> ðŸ’¡ **Tip**: For best results, run the script during non-peak hours to avoid rate limiting by note.com or Notion API.